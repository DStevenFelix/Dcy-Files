本周任务：自学cs188内容并且完成消息机制的学习
完成情况:
1、约束满足问题:使得所有约束均满足的问题
CSP:包括三个成分
X：变量集合 （variables）
D：值域集合，每个变量有自己的值域 （domain）
C：描述变量取值的约束集合 （constraint）
澳大利亚地图染色:【相邻区域的颜色不可以相同】
利用回溯搜索【对于DFS的最优化】
选择变量的策略
1:MRV启发式
2:度启发式
3:最小约束值启发式



2、对抗搜索
1：Minimax算法

将双方决策过程视作一颗决策树，若决策树某一层均为己方决策依据状态（即接下来是己方进行动作），则己方必定会选择使得己方收益最大化的路径，将该层称为MAX层。若决策树某一层均为对手决策依据状态（即接下来是对手进行动作），则对手必定会选择使得己方收益最小化的路径，将该层成为MIN层。由此，一个极小化极大决策树将包含max节点（MAX层中的节点）、min节点（MIN层中的节点）和终止节点（博弈终止状态节点或N步时的状态节点）。每个节点对应的预期收益成为该节点的minimax值。
对于终止结点， minimax值等于直接对局面的估值。对于max结点，由于max节点所选择的动作将会由己方给定，因此选择minimax值最大的子结点的值作为max结点的值。对于min结点，则选择minimax值最小的子结点的值作为min结点的值。

流程为:
构建决策树；
将评估函数应用于叶子结点；
自底向上计算每个结点的minimax值；
从根结点选择minimax值最大的分支，作为行动策略。
minimax计算流程如下：

如果节点是终止节点：应用估值函数求值；
如果节点是max节点：找到每个子节点的值，将其中最大的子节点值作为该节点的值；
如果节点时min节点：找到每个子节点的值，将其中最小的子节点值作为该节点的值。

2：α-β剪枝

1. Max层的α = max(α， 它的所有子结点的评价值)，Max层的β = 它的父结点的β
2. Min层的β = min(β， 它的所有子结点的评价值)，Min层的 α = 它的父结点的α
3. 当某个结点的 α >= β，停止搜索该节点的其他子结点
4. 叶结点没有 α 和  β

若Max层中发现有一个子结点的评价值比当前所能达到的评价值更大，换句话说就是子结点的操作更优，那么将当前所能达到的评价值换成该子节点的评价值。并且由于它的父结点是从该Max层中选择最小的评价值，那么他就要判断一下当前的α是否大于它父结点的β。为了方便起见，我们将父结点的β赋给它自己的β，这样我们只需要比较它自己的α和β就可以了。
跟第一条类似，如果发现子结点中有比当前更优的操作（对对手更优，即对自己更差），那么就替换β，同时比较父结点最优解与当前解的大小，如果父结点已经有一个更优解，则不必继续搜索了。
Max层中，若某个结点的最优解已经大于它的父结点的最差解，则不必继续搜索，剪枝；Min层中，若某个结点的最差解已经小于它的父结点的最优解，则不必继续搜索，剪枝。
由于叶结点没有子结点，自然不需要计算 α 和 β。


3、依照上周学长所讲编写了获取历史位置的Tool，并在每一个UpdateInfo阶段获取历史位置。

4、消息机制的学习但是上次学长讲完之后有点忘记怎么进行消息的收发

问题:对于消息机制的使用不太熟悉同时对于不同种消息如何进行编码也不了解，例如对于Double，Float,Bool型的数据如何进行编码。



